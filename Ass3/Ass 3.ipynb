{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-484: Intro to ML - Assignment 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Jorge Gonzalez Lopez\n",
    "### CWID: A20474413\n",
    "### Semester: Spring 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as stats\n",
    "import scipy\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('claim_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df[['CAR_TYPE','OCCUPATION','EDUCATION', 'CAR_USE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Total number of samples', len(columns),'\\n')\n",
    "#print('Percentage of Target Values: \\n')\n",
    "\n",
    "probs_targ = columns['CAR_USE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) The entropy of the root node is:  0.9489621493401781\n"
     ]
    }
   ],
   "source": [
    "E_target = np.sum(-probs_targ * np.log2(probs_targ))\n",
    "print('a) The entropy of the root node is: ', E_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_occ = []\n",
    "for i in range(1,len(columns[\"OCCUPATION\"].unique())):\n",
    "    comb_occ+=list(combinations(columns[\"OCCUPATION\"].unique(),i))\n",
    "\n",
    "comb_type = []\n",
    "for i in range(1,len(columns[\"CAR_TYPE\"].unique())):\n",
    "    comb_type+=list(combinations(columns[\"CAR_TYPE\"].unique(),i))\n",
    "    \n",
    "comb_edu = [(\"Below High School\",),(\"Below High School\",\"High School\",),(\"Below High School\",\"High School\",\"Bachelors\",),(\"Below High School\",\"High School\",\"Bachelors\",\"Masters\",)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_split(df,column,target,combinations):\n",
    "    \n",
    "    best_split = []\n",
    "    Gain = 0\n",
    "    split_entropy = 1\n",
    "    \n",
    "    #Get entropy of target value of all the samples in the dataset df\n",
    "    probs_targ = df[target].value_counts(normalize=True)\n",
    "    E_target = np.sum(-probs_targ * np.log2(probs_targ))    \n",
    "    \n",
    "    #For all possible combinations:\n",
    "    for comb in combinations:\n",
    "           \n",
    "        #transform the combination into an array -> left split\n",
    "        split_1 = []\n",
    "        for values in comb:\n",
    "            split_1.append(values)\n",
    "            \n",
    "        #Get the array for the values of the column no included in the combination -> right split\n",
    "        split_2 = [ele for ele in df[column].unique() if ele not in split_1] \n",
    "        \n",
    "        # Subgroup 1: dataset which values of column are contain in split1\n",
    "        # Get probabilities of being Private / Commercial for subgroup1\n",
    "        sub1 = df[df[column].isin(split_1)][target].value_counts(normalize=True)\n",
    "        #Entropy of subgroup1\n",
    "        E_1 = np.sum(-sub1 * np.log2(sub1))\n",
    "        \n",
    "        # Subgroup 2: dataset which values of column are contain in split2\n",
    "        # Get probabilities of being Private / Commercial for subgroup2\n",
    "        sub2 = df[df[column].isin(split_2)][target].value_counts(normalize=True)\n",
    "        #Entropy of subgroup2\n",
    "        E_2 = np.sum(-sub2 * np.log2(sub2))\n",
    "        \n",
    "        # Total number of samples in both subgroups\n",
    "        T1 = len(df[df[column].isin(split_1)][target])\n",
    "        T2 = len(df[df[column].isin(split_2)][target])\n",
    "        \n",
    "        # Calculate the split entropy (both entropies scale by the probability of ocurrence)\n",
    "        E_s = E_1 * T1 / (T1+T2) + E_2 * T2 / (T1+T2)\n",
    "        \n",
    "        # Check and Store the split that gets the lower split entropy\n",
    "        if E_s < split_entropy:\n",
    "            Gain = E_target-E_s\n",
    "            best_split = [split_1, split_2]\n",
    "            split_entropy = E_s\n",
    "            \n",
    "    return best_split, split_entropy, Gain\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "b) Left Split, Right Split, Entropy, Gain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nb) Left Split, Right Split, Entropy, Gain\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['Minivan', 'SUV', 'Sports Car'], ['Van', 'Panel Truck', 'Pickup']], 0.7684152303050842, 0.1805469190350939)\n"
     ]
    }
   ],
   "source": [
    "print(get_optimal_split(columns,'CAR_TYPE','CAR_USE',comb_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Blue Collar', 'Unknown', 'Student'], ['Professional', 'Manager', 'Clerical', 'Doctor', 'Lawyer', 'Home Maker']] 0.7125832535737261 0.236378895766452\n"
     ]
    }
   ],
   "source": [
    "best_split, ent, gain = get_optimal_split(columns,'OCCUPATION','CAR_USE',comb_occ)\n",
    "print(best_split, ent, gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['Below High School'], ['Doctors', 'High School', 'Bachelors', 'Masters']], 0.9356142508258438, 0.013347898514334267)\n"
     ]
    }
   ],
   "source": [
    "print(get_optimal_split(columns,'EDUCATION','CAR_USE',comb_edu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C) OCCUPATION is the feature selected for splitting the first layer\n"
     ]
    }
   ],
   "source": [
    "print('C) OCCUPATION is the feature selected for splitting the first layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Left Branch\n"
     ]
    }
   ],
   "source": [
    "print('\\n Left Branch')\n",
    "\n",
    "# DATASET LEFT BRANCH: samples that meet the split condition\n",
    "Left_branch = columns[columns['OCCUPATION'].isin(best_split[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['Minivan', 'SUV', 'Sports Car'], ['Van', 'Panel Truck', 'Pickup']], 0.7725782837913744, 0.08232012008258416)\n"
     ]
    }
   ],
   "source": [
    "print(get_optimal_split(Left_branch,'CAR_TYPE','CAR_USE',comb_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['Student'], ['Blue Collar', 'Unknown']], 0.8042192219461466, 0.050679181927811956)\n"
     ]
    }
   ],
   "source": [
    "comb_occ2 = []\n",
    "for i in range(1,len(best_split[0])):\n",
    "    comb_occ2+=list(combinations(best_split[0],i))\n",
    "\n",
    "print(get_optimal_split(Left_branch,'OCCUPATION','CAR_USE',comb_occ2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Below High School'], ['High School', 'Bachelors', 'Doctors', 'Masters']] 0.6670194998377932 0.18787890403616536\n"
     ]
    }
   ],
   "source": [
    "best_split_l, ent, gain = get_optimal_split(Left_branch,'EDUCATION','CAR_USE',comb_edu)\n",
    "\n",
    "print(best_split_l, ent, gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Right Branch\n"
     ]
    }
   ],
   "source": [
    "print('\\n Right Branch')\n",
    "\n",
    "# DATASET RIGHT BRANCH: samples that do not meet the split condition\n",
    "right_branch = columns[columns['OCCUPATION'].isin(best_split[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Minivan', 'SUV', 'Sports Car'], ['Van', 'Pickup', 'Panel Truck']] 0.3274450052616846 0.3001463166908794\n"
     ]
    }
   ],
   "source": [
    "best_split_r, ent, gain = get_optimal_split(right_branch,'CAR_TYPE','CAR_USE',comb_type)\n",
    "\n",
    "print(best_split_r, ent, gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['Professional'], ['Minivan', 'Van', 'SUV', 'Sports Car', 'Pickup', 'Panel Truck']], 0.627591321952564, 0.0)\n"
     ]
    }
   ],
   "source": [
    "comb_occ2 = []\n",
    "for i in range(1,len(best_split[1])):\n",
    "    comb_occ2+=list(combinations(best_split[1],i))\n",
    "\n",
    "print(get_optimal_split(right_branch,'CAR_TYPE','CAR_USE',comb_occ2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['Below High School'], ['Minivan', 'Van', 'SUV', 'Sports Car', 'Pickup', 'Panel Truck']], 0.627591321952564, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(get_optimal_split(right_branch,'CAR_TYPE','CAR_USE',comb_edu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Terminal Nodes\n"
     ]
    }
   ],
   "source": [
    "print('\\nTerminal Nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAST DATASETS: \n",
    "# samples that meet the split condition\n",
    "left_left = Left_branch[Left_branch['EDUCATION'].isin(best_split_l[0])]\n",
    "# samples that do not meet the split condition\n",
    "left_right = Left_branch[Left_branch['EDUCATION'].isin(best_split_l[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAST DATASETS: \n",
    "# samples that meet the split condition\n",
    "right_left = right_branch[right_branch['CAR_TYPE'].isin(best_split_r[0])]\n",
    "# samples that do not meet the split condition\n",
    "right_right = right_branch[right_branch['CAR_TYPE'].isin(best_split_r[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_nodes(df, target):\n",
    "    #Get the total number of Private / Commercial (target categories) samples in df\n",
    "    count = df[target].value_counts()\n",
    "    #Get the probability of Private / Commercial (target categories) in df\n",
    "    probs_targ = df[target].value_counts(normalize=True)\n",
    "    # Calculate the entropy\n",
    "    E = np.sum(-probs_targ * np.log2(probs_targ))\n",
    "    return E, count, probs_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Terminal node: Entropy:  0.8304276080710689 . Private:  607 . Commercial:  216 . Total:  823 Probabilties of Private:  0.7375455650060754 Probabilties of Commercial:  0.2624544349939247\n",
      "\n",
      "2. Terminal node: Entropy:  0.6226204001098349 . Private:  2559 . Commercial:  470 . Total:  3029 Probabilties of Private:  0.8448332783096731 Probabilties of Commercial:  0.15516672169032683\n",
      "\n",
      "3. Terminal node: Entropy:  0.056791153992247115 . Private:  4564 . Commercial:  30 . Total:  4594 Probabilties of Private:  0.9934697431432303 Probabilties of Commercial:  0.006530256856769699\n",
      "\n",
      "4. Terminal node: Entropy:  0.9973716177249364 . Private:  984 . Commercial:  872 . Total:  1856 Probabilties of Private:  0.5301724137931034 Probabilties of Commercial:  0.4698275862068966\n"
     ]
    }
   ],
   "source": [
    "E, count, prob = terminal_nodes(left_left, 'CAR_USE')\n",
    "print('\\n1. Terminal node: Entropy: ', E, '. Private: ' ,count[0], '. Commercial: ' ,count[1],'. Total: ' ,count[0]+count[1], 'Probabilties of Private: ', prob[0],'Probabilties of Commercial: ', prob[1] )\n",
    "E, count, prob = terminal_nodes(left_right, 'CAR_USE')\n",
    "print('\\n2. Terminal node: Entropy: ', E, '. Private: ' ,count[0], '. Commercial: ' ,count[1],'. Total: ' ,count[0]+count[1], 'Probabilties of Private: ', prob[0],'Probabilties of Commercial: ', prob[1] )\n",
    "E, count, prob = terminal_nodes(right_left, 'CAR_USE')\n",
    "print('\\n3. Terminal node: Entropy: ', E, '. Private: ' ,count[0], '. Commercial: ' ,count[1],'. Total: ' ,count[0]+count[1], 'Probabilties of Private: ', prob[0],'Probabilties of Commercial: ', prob[1] )\n",
    "E, count, prob = terminal_nodes(right_right, 'CAR_USE')\n",
    "print('\\n4. Terminal node: Entropy: ', E, '. Private: ' ,count[0], '. Commercial: ' ,count[1],'. Total: ' ,count[0]+count[1], 'Probabilties of Private: ', prob[0],'Probabilties of Commercial: ', prob[1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_v10.csv')\n",
    "df['y'] = df['y'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) The frequency table of the categorical target field is: \n",
      "3    4194\n",
      "2    3532\n",
      "1    2274\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('a) The frequency table of the categorical target field is: ')\n",
    "print(df['y'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195606\n",
      "         Iterations 10\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                10000\n",
      "Model:                        MNLogit   Df Residuals:                     9978\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Sun, 07 Mar 2021   Pseudo R-squ.:                  0.8170\n",
      "Time:                        18:24:15   Log-Likelihood:                -1956.1\n",
      "converged:                       True   LL-Null:                       -10688.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "       y=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0165      0.087     11.636      0.000       0.845       1.188\n",
      "x1            -1.1172      0.058    -19.343      0.000      -1.230      -1.004\n",
      "x2            -0.0175      0.026     -0.669      0.503      -0.069       0.034\n",
      "x3             0.0103      0.018      0.586      0.558      -0.024       0.045\n",
      "x4            -1.5573      0.041    -38.103      0.000      -1.637      -1.477\n",
      "x5             0.0030      0.010      0.287      0.774      -0.018       0.024\n",
      "x6             0.0163      0.009      1.822      0.068      -0.001       0.034\n",
      "x7         -1.268e-07      0.007   -1.7e-05      1.000      -0.015       0.015\n",
      "x8            -0.0134      0.007     -2.028      0.043      -0.026      -0.000\n",
      "x9             0.0076      0.006      1.315      0.189      -0.004       0.019\n",
      "x10            0.0072      0.009      0.804      0.421      -0.010       0.025\n",
      "------------------------------------------------------------------------------\n",
      "       y=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4041      0.106      3.817      0.000       0.197       0.612\n",
      "x1            -1.1685      0.071    -16.354      0.000      -1.309      -1.028\n",
      "x2             0.0002      0.033      0.005      0.996      -0.064       0.064\n",
      "x3            -0.0009      0.022     -0.041      0.968      -0.045       0.043\n",
      "x4            -0.0218      0.027     -0.794      0.427      -0.075       0.032\n",
      "x5            -0.0088      0.013     -0.671      0.503      -0.034       0.017\n",
      "x6             0.0004      0.011      0.038      0.970      -0.021       0.022\n",
      "x7            -0.0017      0.010     -0.179      0.858      -0.021       0.017\n",
      "x8            -0.0072      0.008     -0.867      0.386      -0.024       0.009\n",
      "x9             0.0024      0.007      0.324      0.746      -0.012       0.017\n",
      "x10            1.3464      0.038     35.838      0.000       1.273       1.420\n",
      "==============================================================================\n",
      "Model Log-Likelihood Value = -1956.0551397480979\n",
      "Number of Free Parameters = 22\n"
     ]
    }
   ],
   "source": [
    "# Backward Selection\n",
    "# Consider Model 0 is Origin = Intercept + DriveTrain + Weight\n",
    "y = df['y']\n",
    "X = df.drop(['y'], axis=1)\n",
    "\n",
    "columns = X.columns\n",
    "\n",
    "X = stats.add_constant(X, prepend=True)\n",
    "\n",
    "DF1 = np.linalg.matrix_rank(X) * (len(y.value_counts()) - 1)\n",
    "\n",
    "logit = stats.MNLogit(y, X)\n",
    "thisFit = logit.fit(method='newton', full_output = True, maxiter = 100, tol = 1e-8)\n",
    "thisParameter = thisFit.params\n",
    "LLK1 = logit.loglike(thisParameter.values)\n",
    "\n",
    "print(thisFit.summary())\n",
    "print(\"Model Log-Likelihood Value =\", LLK1)\n",
    "print(\"Number of Free Parameters =\", DF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195606\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222527\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195633\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195628\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578049\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195647\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195808\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195607\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195811\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195695\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811114\n",
      "         Iterations 7\n",
      "\n",
      "Model 1  --> Removed feature:  ['x7']\n",
      "Model Log-Likelihood Value = -1956.0744283318356\n",
      "Number of Free Parameters = 20\n",
      "Deviance (Statistic, DF, Significance) 0.03857716747552331 2 0.9808962506876956\n",
      "Akaike Information Criterion = 3952.1488566636713\n",
      "Bayesian Information Criterion = 4096.355664103195\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195607\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222534\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195635\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195630\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578085\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195649\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195810\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195813\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195698\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811162\n",
      "         Iterations 7\n",
      "\n",
      "Model 2  --> Removed feature:  ['x7', 'x3']\n",
      "Model Log-Likelihood Value = -1956.30232999277\n",
      "Number of Free Parameters = 18\n",
      "Deviance (Statistic, DF, Significance) 0.45580332186864325 2 0.7962025538009445\n",
      "Akaike Information Criterion = 3948.60465998554\n",
      "Bayesian Information Criterion = 4078.3907866811114\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195630\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222539\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195659\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578097\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195672\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195831\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195832\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195723\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811224\n",
      "         Iterations 7\n",
      "\n",
      "Model 3  --> Removed feature:  ['x7', 'x3', 'x2']\n",
      "Model Log-Likelihood Value = -1956.5870772945038\n",
      "Number of Free Parameters = 16\n",
      "Deviance (Statistic, DF, Significance) 0.5694946034677741 2 0.7522043110300307\n",
      "Akaike Information Criterion = 3945.1741545890077\n",
      "Bayesian Information Criterion = 4060.5396005406265\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195659\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222554\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578139\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195700\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195854\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195867\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195751\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811264\n",
      "         Iterations 7\n",
      "\n",
      "Model 4  --> Removed feature:  ['x7', 'x3', 'x2', 'x5']\n",
      "Model Log-Likelihood Value = -1956.9994039437684\n",
      "Number of Free Parameters = 14\n",
      "Deviance (Statistic, DF, Significance) 0.8246532985290287 2 0.6621079636455474\n",
      "Akaike Information Criterion = 3941.9988078875367\n",
      "Bayesian Information Criterion = 4042.943573095203\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195700\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222603\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578215\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195900\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195909\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195795\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811295\n",
      "         Iterations 7\n",
      "\n",
      "Model 5  --> Removed feature:  ['x7', 'x3', 'x2', 'x5', 'x9']\n",
      "Model Log-Likelihood Value = -1957.9473654299018\n",
      "Number of Free Parameters = 12\n",
      "Deviance (Statistic, DF, Significance) 1.895922972266817 2 0.38753020449855446\n",
      "Akaike Information Criterion = 3939.8947308598035\n",
      "Bayesian Information Criterion = 4026.4188153235177\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195795\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222662\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578236\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195996\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195999\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811307\n",
      "         Iterations 7\n",
      "\n",
      "Model 6  --> Removed feature:  ['x7', 'x3', 'x2', 'x5', 'x9', 'x6']\n",
      "Model Log-Likelihood Value = -1959.9572147343606\n",
      "Number of Free Parameters = 10\n",
      "Deviance (Statistic, DF, Significance) 4.019698608917679 2 0.13400886768610418\n",
      "Akaike Information Criterion = 3939.914429468721\n",
      "Bayesian Information Criterion = 4012.017833188483\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195996\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222884\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578618\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.196190\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811880\n",
      "         Iterations 7\n",
      "\n",
      "Model 7  --> Removed feature:  ['x7', 'x3', 'x2', 'x5', 'x9', 'x6', 'x8']\n",
      "Model Log-Likelihood Value = -1961.9026108507444\n",
      "Number of Free Parameters = 8\n",
      "Deviance (Statistic, DF, Significance) 3.8907922327675806 2 0.1429305949727081\n",
      "Akaike Information Criterion = 3939.805221701489\n",
      "Bayesian Information Criterion = 3997.4879446772984\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.196190\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.223041\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578737\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811988\n",
      "         Iterations 7\n",
      "\n",
      " Best model --> Removed feature:  ['x7', 'x3', 'x2', 'x5', 'x9', 'x6', 'x8']\n",
      "Model Log-Likelihood Value = -2230.4083138546557\n",
      "Number of Free Parameters = 6\n",
      "Deviance (Statistic, DF, Significance) 537.0114060078226 2 2.4516294286009425e-117\n",
      "Akaike Information Criterion = 4472.816627709311\n",
      "Bayesian Information Criterion = 4516.078669941168\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "removed_columns = []\n",
    "best_model = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    y = df['y']\n",
    "    X = df.drop(['y'], axis=1)\n",
    "    X = X.drop(removed_columns, axis = 1)\n",
    "    \n",
    "    columns = X.columns\n",
    "    \n",
    "    X = stats.add_constant(X, prepend=True)\n",
    "\n",
    "    DF1 = np.linalg.matrix_rank(X) * (len(y.value_counts()) - 1)\n",
    "\n",
    "    logit = stats.MNLogit(y, X)\n",
    "    thisFit = logit.fit(method='newton', full_output = True, maxiter = 100, tol = 1e-8)\n",
    "    thisParameter = thisFit.params\n",
    "    LLK1 = logit.loglike(thisParameter.values)\n",
    "\n",
    "    worse_col = []\n",
    "    bigger_pvalue = 0\n",
    "    LLK0_saved = 0\n",
    "    DF0_saved = 0\n",
    "    Dev_saved = 0\n",
    "    DF_saved = 0\n",
    "    AIC_saved = 0\n",
    "    BIC_saved = 0\n",
    "    \n",
    "    \n",
    "    for col in columns:\n",
    "\n",
    "        X2 = X.drop(col, axis = 1)\n",
    "        X2 = stats.add_constant(X2, prepend=True)\n",
    "\n",
    "        DF0 = np.linalg.matrix_rank(X2) * (len(y.value_counts()) - 1)\n",
    "\n",
    "        logit = stats.MNLogit(y, X2)\n",
    "        thisFit = logit.fit(method='newton', full_output = True, maxiter = 100, tol = 1e-8)\n",
    "        thisParameter = thisFit.params\n",
    "        LLK0 = logit.loglike(thisParameter.values)\n",
    "\n",
    "        Deviance = 2 * (LLK1 - LLK0)\n",
    "        DF = DF1 - DF0\n",
    "        pValue = scipy.stats.chi2.sf(Deviance, DF)\n",
    "        \n",
    "        MDF = (thisFit.J - 1) * thisFit.K\n",
    "        LLK = thisFit.llf\n",
    "\n",
    "        NSample = len(y)\n",
    "        AIC = 2.0 * MDF - 2.0 * LLK\n",
    "        BIC = MDF * np.log(NSample) - 2.0 * LLK\n",
    "\n",
    "        if pValue > bigger_pvalue:\n",
    "            worse_col = col\n",
    "            bigger_pvalue = pValue\n",
    "            LLK0_saved = LLK0\n",
    "            DF0_saved = DF0\n",
    "            Dev_saved = Deviance\n",
    "            DF_saved = DF\n",
    "            AIC_saved = AIC\n",
    "            BIC_saved = BIC\n",
    "\n",
    "    \n",
    "    if bigger_pvalue < 0.05:\n",
    "        best_model = X2.columns\n",
    "        print('\\n Best model --> Removed feature: ', removed_columns)\n",
    "        print(\"Model Log-Likelihood Value =\", LLK0_saved)\n",
    "        print(\"Number of Free Parameters =\", DF0_saved)\n",
    "        print(\"Deviance (Statistic, DF, Significance)\", Dev_saved, DF_saved, bigger_pvalue)\n",
    "        print(\"Akaike Information Criterion =\", AIC_saved)\n",
    "        print(\"Bayesian Information Criterion =\", BIC_saved)\n",
    "        print('\\n')\n",
    "        break\n",
    "    \n",
    "    removed_columns.append(worse_col)\n",
    "    print('\\nModel', i, ' --> Removed feature: ', removed_columns)\n",
    "    print(\"Model Log-Likelihood Value =\", LLK0_saved)\n",
    "    print(\"Number of Free Parameters =\", DF0_saved)\n",
    "    print(\"Deviance (Statistic, DF, Significance)\", Dev_saved, DF_saved, bigger_pvalue)\n",
    "    print(\"Akaike Information Criterion =\", AIC_saved)\n",
    "    print(\"Bayesian Information Criterion =\", BIC_saved)    \n",
    "    print('\\n')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.196190\n",
      "         Iterations 10\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                10000\n",
      "Model:                        MNLogit   Df Residuals:                     9992\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Tue, 02 Mar 2021   Pseudo R-squ.:                  0.8164\n",
      "Time:                        23:50:35   Log-Likelihood:                -1961.9\n",
      "converged:                       True   LL-Null:                       -10688.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "       y=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0168      0.087     11.675      0.000       0.846       1.188\n",
      "x1            -1.1145      0.058    -19.332      0.000      -1.227      -1.001\n",
      "x4            -1.5540      0.041    -38.203      0.000      -1.634      -1.474\n",
      "x10            0.0073      0.009      0.811      0.417      -0.010       0.025\n",
      "------------------------------------------------------------------------------\n",
      "       y=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4064      0.105      3.857      0.000       0.200       0.613\n",
      "x1            -1.1664      0.071    -16.350      0.000      -1.306      -1.027\n",
      "x4            -0.0224      0.027     -0.821      0.412      -0.076       0.031\n",
      "x10            1.3449      0.037     35.922      0.000       1.272       1.418\n",
      "==============================================================================\n",
      "Model Log-Likelihood Value = -1961.9026108507444\n",
      "Number of Free Parameters = 8\n"
     ]
    }
   ],
   "source": [
    "y = df['y']\n",
    "X2 = df.drop(['y'], axis=1)\n",
    "X2 = X.drop(removed_columns, axis=1)\n",
    "X2 = stats.add_constant(X2, prepend=True)\n",
    "\n",
    "DF1 = np.linalg.matrix_rank(X2) * (len(y.value_counts()) - 1)\n",
    "\n",
    "logit = stats.MNLogit(y, X2)\n",
    "thisFit = logit.fit(method='newton', full_output = True, maxiter = 100, tol = 1e-8)\n",
    "thisParameter = thisFit.params\n",
    "LLK1 = logit.loglike(thisParameter.values)\n",
    "\n",
    "print(thisFit.summary())\n",
    "print(\"Model Log-Likelihood Value =\", LLK1)\n",
    "print(\"Number of Free Parameters =\", DF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222527\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  x1\n",
      "Akaike Information Criterion = 4490.542699405585\n",
      "Bayesian Information Criterion = 4634.749506845109\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195633\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  x2\n",
      "Akaike Information Criterion = 3952.662121276995\n",
      "Bayesian Information Criterion = 4096.868928716519\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195628\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  x3\n",
      "Akaike Information Criterion = 3952.560725487029\n",
      "Bayesian Information Criterion = 4096.767532926552\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578049\n",
      "         Iterations 9\n",
      "\n",
      "Model 1 --> Removed feature:  x4\n",
      "Akaike Information Criterion = 11600.988729969893\n",
      "Bayesian Information Criterion = 11745.195537409416\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195647\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  x5\n",
      "Akaike Information Criterion = 3952.9403873874453\n",
      "Bayesian Information Criterion = 4097.147194826969\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195808\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  x6\n",
      "Akaike Information Criterion = 3956.1671105582254\n",
      "Bayesian Information Criterion = 4100.373917997749\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195607\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  x7\n",
      "Akaike Information Criterion = 3952.1488566636713\n",
      "Bayesian Information Criterion = 4096.355664103195\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195811\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  x8\n",
      "Akaike Information Criterion = 3956.229529239344\n",
      "Bayesian Information Criterion = 4100.4363366788675\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.195695\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  x9\n",
      "Akaike Information Criterion = 3953.9064614025046\n",
      "Bayesian Information Criterion = 4098.113268842028\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.811114\n",
      "         Iterations 7\n",
      "\n",
      "Model 1 --> Removed feature:  x10\n",
      "Akaike Information Criterion = 16262.273584255823\n",
      "Bayesian Information Criterion = 16406.480391695346\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "\n",
    "    X2 = X.drop(col, axis = 1)\n",
    "    X2 = stats.add_constant(X2, prepend=True)\n",
    "    \n",
    "    objLogit = stats.MNLogit(y, X2)\n",
    "    thisFit = objLogit.fit(method = 'newton', maxiter = 100, tol = 1e-8)\n",
    "\n",
    "    MDF = (thisFit.J - 1) * thisFit.K\n",
    "    LLK = thisFit.llf\n",
    "    \n",
    "    NSample = len(y)\n",
    "    AIC = 2.0 * MDF - 2.0 * LLK\n",
    "    BIC = MDF * np.log(NSample) - 2.0 * LLK\n",
    "    \n",
    "    print('\\nModel 1 --> Removed feature: ', col)\n",
    "    #print(thisFit.summary())\n",
    "    print(\"Akaike Information Criterion =\", AIC)\n",
    "    print(\"Bayesian Information Criterion =\", BIC)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.196190\n",
      "         Iterations 10\n",
      "\n",
      "Model 1 --> Removed feature:  ['x2', 'x3', 'x5', 'x6', 'x7', 'x8', 'x9']\n",
      "Akaike Information Criterion = 3939.805221701489\n",
      "Bayesian Information Criterion = 3997.4879446772984\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X2 = X.drop(removed_columns, axis = 1)\n",
    "X2 = stats.add_constant(X2, prepend=True)\n",
    "\n",
    "objLogit = stats.MNLogit(y, X2)\n",
    "thisFit = objLogit.fit(method = 'newton', maxiter = 100, tol = 1e-8)\n",
    "\n",
    "MDF = (thisFit.J - 1) * thisFit.K\n",
    "LLK = thisFit.llf\n",
    "\n",
    "NSample = len(y)\n",
    "AIC = 2.0 * MDF - 2.0 * LLK\n",
    "BIC = MDF * np.log(NSample) - 2.0 * LLK\n",
    "\n",
    "print('\\nModel 1 --> Removed feature: ', removed_columns)\n",
    "#print(thisFit.summary())\n",
    "print(\"Akaike Information Criterion =\", AIC)\n",
    "print(\"Bayesian Information Criterion =\", BIC)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
